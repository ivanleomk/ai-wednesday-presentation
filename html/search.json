[
  {
    "objectID": "slides.html#who-am-i",
    "href": "slides.html#who-am-i",
    "title": "What’s Next for LLMs",
    "section": "Who am I",
    "text": "Who am I\nI am currently a Research Engineer at 567 Labs. We primarily work with companies looking to scale out their machine learning capabilities. We help at all stages of this, from hiring to prototyping and high level design.\nI do some open source on the side and help mantain Instructor - a python package that makes it easy to use LLMs to extract structured data ( More on this ). I mostly code in Python nowadays but am moving to do more Rust. ( Instructor is releasing a rust package soon! )"
  },
  {
    "objectID": "slides.html#whats-new",
    "href": "slides.html#whats-new",
    "title": "What’s Next for LLMs",
    "section": "What’s New",
    "text": "What’s New\nLast year we saw a lot of experimentation, this year with more funding and interest in the space, the goal has shifted to making them more reliable, consistent and secure."
  },
  {
    "objectID": "slides.html#definitions",
    "href": "slides.html#definitions",
    "title": "What’s Next for LLMs",
    "section": "Definitions",
    "text": "Definitions\nThere are three things that will come up a lot in my talk\n\nAgents - Systems that are able to make a decision based on some input\nEvaluations - a set of metrics to understand where our system falls short (Eg. Precision and Recall)\nSynthethic Data Generation - Data generated by a LLM that’s meant to mimic some form of real data"
  },
  {
    "objectID": "slides.html#big-picture",
    "href": "slides.html#big-picture",
    "title": "What’s Next for LLMs",
    "section": "Big Picture",
    "text": "Big Picture\nHow does this come together?\n\nAs we deploy more LLMs in productions, we’ll start using more systems with agentic behaviour.\nThis will be a complex process so we’ll start developing more sophisticated evaluations to understand each component of this process.\nAnd ultimately when we want to invest time into improving capabilities of specific components of these systems, we’ll use synthethic data to make sure our system is robust and reliable."
  },
  {
    "objectID": "slides.html#structured-extraction",
    "href": "slides.html#structured-extraction",
    "title": "What’s Next for LLMs",
    "section": "Structured Extraction",
    "text": "Structured Extraction\nThis means that we need a consistent way to ensure that our systems are reliable and consistent.\nI think Structured Extraction is the way to go when it comes to this, that’s what Instructor solves."
  },
  {
    "objectID": "slides.html#how-does-this-look-like",
    "href": "slides.html#how-does-this-look-like",
    "title": "What’s Next for LLMs",
    "section": "How does this look like?",
    "text": "How does this look like?\nIt’s pretty straightforward, basically you make a function call and get back a validated output\nimport instructor\nfrom pydantic import BaseModel\nfrom openai import OpenAI\n\n\n# Define your desired output structure\nclass UserInfo(BaseModel):\n    name: str\n    age: int\n\n\n# Patch the OpenAI client\nclient = instructor.from_openai(OpenAI())\n\n# Extract structured data from natural language\nuser_info = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=UserInfo,\n    messages=[{\"role\": \"user\", \"content\": \"John Doe is 30 years old.\"}],\n)\n\nprint(user_info.name)\n#&gt; John Doe\nprint(user_info.age)\n#&gt; 30"
  },
  {
    "objectID": "slides.html#tldr",
    "href": "slides.html#tldr",
    "title": "What’s Next for LLMs",
    "section": "Tl;Dr",
    "text": "Tl;Dr\nIn short, you can express LLM calls as a typed function, not unlike a traditional function call\ndef function() -&gt; str:\n    return \"Hello, World!\""
  },
  {
    "objectID": "slides.html#agents",
    "href": "slides.html#agents",
    "title": "What’s Next for LLMs",
    "section": "Agents",
    "text": "Agents\nInstead of encoding in hard logic that is brittle when the input changes, we can instead provide a model with some context and let it make decisions in a fuzzier manner.\nThis is acceptable for some specific processes and helps in overall adaptability."
  },
  {
    "objectID": "slides.html#what-happened-last-year",
    "href": "slides.html#what-happened-last-year",
    "title": "What’s Next for LLMs",
    "section": "What happened last Year?",
    "text": "What happened last Year?"
  },
  {
    "objectID": "slides.html#what-was-the-main-problem",
    "href": "slides.html#what-was-the-main-problem",
    "title": "What’s Next for LLMs",
    "section": "What was the main problem",
    "text": "What was the main problem\nLibraries such as BabyAGI and Langchain enabled people to chain together complex iterations. But, these agents often lacked conconistency and reliability with the open ended ReACT methodology."
  },
  {
    "objectID": "slides.html#sample-react-prompt",
    "href": "slides.html#sample-react-prompt",
    "title": "What’s Next for LLMs",
    "section": "Sample React Prompt",
    "text": "Sample React Prompt"
  },
  {
    "objectID": "slides.html#whats-the-problem-with-this",
    "href": "slides.html#whats-the-problem-with-this",
    "title": "What’s Next for LLMs",
    "section": "What’s the problem with this?",
    "text": "What’s the problem with this?\nThe main problem with the ReAct methodology is that it’s too open ended. It’s difficult to accurately evaluate where the agent might have gone wrong or if there was a better approach sometimes\nIn short it was\n\nDifficult to evaluate the quality of the agent\nDifficult to understand the reasoning behind the agent’s decisions\nDifficult to debug and improve the agent"
  },
  {
    "objectID": "slides.html#whats-the-problem-with-this-1",
    "href": "slides.html#whats-the-problem-with-this-1",
    "title": "What’s Next for LLMs",
    "section": "What’s the problem with this?",
    "text": "What’s the problem with this?\nA lot of these agents would loop for 6 hours, give you a $80 OpenAI Bill and not get anything done."
  },
  {
    "objectID": "slides.html#a-better-way",
    "href": "slides.html#a-better-way",
    "title": "What’s Next for LLMs",
    "section": "A better way",
    "text": "A better way\nInstead, this year we’ve seen a shift from a view agents as autonomous systems that have full autonomy without guardrails to more complex fuzzy decision making proceses."
  },
  {
    "objectID": "slides.html#broad-trends",
    "href": "slides.html#broad-trends",
    "title": "What’s Next for LLMs",
    "section": "Broad Trends",
    "text": "Broad Trends\nThere are a few broad reasons why this is happening\n\nThey’re easier to test - assert func is called is much easier to reason about than a complex ReAct Loop\nIt’s much easier to scale multi-agent systems (Since they now output structured data)\nWe can integreate them easily with existing systems with significantly less effort"
  },
  {
    "objectID": "slides.html#evaluations",
    "href": "slides.html#evaluations",
    "title": "What’s Next for LLMs",
    "section": "Evaluations",
    "text": "Evaluations\nEvaluations were huge this year.\nHistorically it’s been difficult to evaluate LLM outputs due to their open-ended nature. Some specific issues that are still unsolved include alignment of styles and hallucinations."
  },
  {
    "objectID": "slides.html#whats-changed",
    "href": "slides.html#whats-changed",
    "title": "What’s Next for LLMs",
    "section": "What’s changed",
    "text": "What’s changed\nA lot more of insight has been gained in the last year.\n\nUse Heuristics : A bigger shift to using heuristics to test systems - Eg. Discord checking to see if the messages produced by their chatbot are casual by verifying if it’s all in lowercase\nLLM as a Judge is Ok : LLM as a judge for fuzzy initial checks - eventually you align it with human preferences with manual annotators creating a test/train dataset for you to train models on"
  },
  {
    "objectID": "slides.html#whats-changed-1",
    "href": "slides.html#whats-changed-1",
    "title": "What’s Next for LLMs",
    "section": "What’s changed",
    "text": "What’s changed\n\nBreak it up : A general consensus that you should break up your evaluation into smaller, more manageable pieces. True/False binary labels are much easier to align and consistent across annotators."
  },
  {
    "objectID": "slides.html#synthethic-data",
    "href": "slides.html#synthethic-data",
    "title": "What’s Next for LLMs",
    "section": "Synthethic Data",
    "text": "Synthethic Data\nGenerating Synthethic Data is easy, generating good synthethic data is hard."
  },
  {
    "objectID": "slides.html#why-synthethic-data",
    "href": "slides.html#why-synthethic-data",
    "title": "What’s Next for LLMs",
    "section": "Why Synthethic Data?",
    "text": "Why Synthethic Data?\nIt’s not because we’re running out of data to train foundation models.\nAs we train and deploy models for niche use cases, it’s increasingly easier to generate synthethic data to test and validate our implementations (Eg. A model that needs to be able to click on buttons on the web or Retrieval for RAG )"
  },
  {
    "objectID": "slides.html#whats-hard-about-it",
    "href": "slides.html#whats-hard-about-it",
    "title": "What’s Next for LLMs",
    "section": "What’s hard about it?",
    "text": "What’s hard about it?\nIt’s extremely difficult to ensure that\n\nOur data is representative of the real world\nOur data is useful for our use case\n\nA great presentation during the conference was by Vikhyatk, who talked about the moondream model"
  },
  {
    "objectID": "slides.html#moondream-intro",
    "href": "slides.html#moondream-intro",
    "title": "What’s Next for LLMs",
    "section": "Moondream Intro",
    "text": "Moondream Intro\nMoondream is a small vision model, with ~1.5 billion parameters. That’s significantly smaller than most models these days.\nThey trained the model with a significant of synthethic data and shared a lot about their insights in generating the training data.\nThe challenge comes when you’re prompting the same model for multiple rounds - it tends to converge on the same topics."
  },
  {
    "objectID": "slides.html#a-bit-more-about-moondream",
    "href": "slides.html#a-bit-more-about-moondream",
    "title": "What’s Next for LLMs",
    "section": "A bit more about Moondream",
    "text": "A bit more about Moondream\n\nInject unique elements into each prompt\n\nExample: Use image alt text for each image\nUse some form of permutation\n\nGenerate absurd questions to help the model learn when to refuse certain questions\n\nExample: Using Mixtral to generate absurd questions\nNote: Mixtral tends to generate questions about Aliens and Dinosaurs, so always review the generated questions"
  },
  {
    "objectID": "slides.html#moondream",
    "href": "slides.html#moondream",
    "title": "What’s Next for LLMs",
    "section": "Moondream",
    "text": "Moondream"
  },
  {
    "objectID": "slides.html#stuctured-extraction",
    "href": "slides.html#stuctured-extraction",
    "title": "What’s Next for LLMs",
    "section": "Stuctured Extraction",
    "text": "Stuctured Extraction\nSo let’s see a potential workload in action - generating synthethic questions\nYou have some existing knowledge base that you’d like to generate synthethic questions from so you can test your retrieval pipeline."
  },
  {
    "objectID": "slides.html#generating-the-questions",
    "href": "slides.html#generating-the-questions",
    "title": "What’s Next for LLMs",
    "section": "Generating the Questions",
    "text": "Generating the Questions\nclass QuestionAnswerPair(BaseModel):\n    \"\"\"\n    This model represents a pair of a question generated \n    from a text chunk, its corresponding answer, and the \n    chain of thought leading to the answer. The chain of \n    thought provides insight into how the answer was \n    derived from the question.\n    \"\"\"\n\n    chain_of_thought: str = Field(\n        description=\"The reasoning process leading to the answer.\"\n    )\n    question: str = Field(\n        description=\"The generated question from the text chunk.\"\n    )\n    answer: str = Field(\n        description=\"The answer to the generated question.\"\n    )"
  },
  {
    "objectID": "slides.html#generating-the-questions-1",
    "href": "slides.html#generating-the-questions-1",
    "title": "What’s Next for LLMs",
    "section": "Generating the Questions",
    "text": "Generating the Questions\nclient = instructor.from_openai(openai.AsyncOpenAI())\n\ndef generate_question(text: str):\n    question = await client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"You are a world class AI that excels at generating hypothethical search queries. \n                You're about to be given a text snippet and asked to generate a search query which is specific \n                to the specific text chunk that you'll be given. Make sure to use information from the text chunk.\"\"\"\n            },\n            {\"role\": \"user\", \"content\": f\"Here is the text chunk : {text}\"},\n        ],\n        response_model=QuestionAnswerPair,\n        max_retries=3,\n    )\n    return (question,text)"
  },
  {
    "objectID": "slides.html#quick-experimentation",
    "href": "slides.html#quick-experimentation",
    "title": "What’s Next for LLMs",
    "section": "Quick Experimentation",
    "text": "Quick Experimentation\nWith a new synthethic dataset, we can now do things such as\n\nUnderstand the kinds of data that is within our query corpus - what specific methods struggle with different text chunks?\nExperiment with different system permutations - what acceptable performance/latency/cost is for a given system?"
  },
  {
    "objectID": "slides.html#evaluating-the-retrieval",
    "href": "slides.html#evaluating-the-retrieval",
    "title": "What’s Next for LLMs",
    "section": "Evaluating the Retrieval",
    "text": "Evaluating the Retrieval\nEvaluating the retrieval is easy since we can quickly generate a large dataset of question to text pairs. This allows us to test metrics such as recall, precision or mrr across a large number of queries easily."
  },
  {
    "objectID": "slides.html#deploying-it-in-production",
    "href": "slides.html#deploying-it-in-production",
    "title": "What’s Next for LLMs",
    "section": "Deploying it in production",
    "text": "Deploying it in production\nDeploying it as a function call in production is easy\nimport instructor\nfrom openai import OpenAI\n\nclient = instructor.from_openai(OpenAI())\n\nclass QueryPlan(BaseModel):\n    sub_queries:list[str]\n\n    def execute_query():\n        ## Retrieval Logic here\n        return \"\"\n\ndef generate_query_plan():\n    return client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a query plan for the user query of {query}\"}\n        ],\n        response_model=QueryPlan,\n    )"
  },
  {
    "objectID": "slides.html#monitoring",
    "href": "slides.html#monitoring",
    "title": "What’s Next for LLMs",
    "section": "Monitoring",
    "text": "Monitoring\nThis gives us a lot of potential ways to monitor the performance of our system.\n\nWe can see the distribution of user queries - how different are the synthethic questions from the actual user queries?\nWe can see if our language model is able to retrieve the relevant chunks ( this needs domain expertise ) and answer questions such as do we need more text material? Do we need to augment our model with new information in the prompt (Eg. specific accronyms that are relevant to the user query)"
  },
  {
    "objectID": "slides.html#monitoring-1",
    "href": "slides.html#monitoring-1",
    "title": "What’s Next for LLMs",
    "section": "Monitoring",
    "text": "Monitoring\n\nWe can see if the specific query planner here is able to generate good queries - do we perhaps need to augment it with something like Splade?\n\nand many more questions"
  },
  {
    "objectID": "slides.html#integration-with-other-systems",
    "href": "slides.html#integration-with-other-systems",
    "title": "What’s Next for LLMs",
    "section": "Integration with other systems",
    "text": "Integration with other systems\nSince our model now outputs a python object that can be serialized to JSON, we can\n\nDo Logging : Dump the output in something like datadog or logfire for post processing\nIntegrate it with other existing systems, just add a requests.post() call to whatever system you’re using. This includes whatever python scripts (or agent if u want to use that term) that you have in mind."
  },
  {
    "objectID": "slides.html#thank-you",
    "href": "slides.html#thank-you",
    "title": "What’s Next for LLMs",
    "section": "Thank you",
    "text": "Thank you\nHappy to chat more. I’m at @ivanleomk on twitter and my email is ivanleomk@gmail.com."
  }
]